{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwjq02MfS4wB4XRPu8F2Jn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasminelong/Classify-Leaves/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtdUFPPsZ91L",
        "outputId": "d4637204-6238-4754-eaa4-2f86da1bad67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations --upgrade\n",
        "!pip install timm\n",
        "!pip install ttach\n",
        "!pip install pytorch-metric-learning\n",
        "!pip install imagehash\n",
        "!pip install torchinfo\n",
        "!pip install torch-lr-finder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDXOmpz_Np8o",
        "outputId": "685ce710-3a3b-44c5-8f12-963fd6c6d255"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.8/dist-packages (1.3.0)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from albumentations) (6.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (4.7.0.72)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from albumentations) (1.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from qudida>=0.0.4->albumentations) (4.5.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from qudida>=0.0.4->albumentations) (1.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (8.4.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.2.27)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (3.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (2.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations) (23.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.8/dist-packages (0.6.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm) (1.13.1+cu116)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.8/dist-packages (from timm) (0.12.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm) (0.14.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (4.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ttach in /usr/local/lib/python3.8/dist-packages (0.0.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-metric-learning in /usr/local/lib/python3.8/dist-packages (2.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from pytorch-metric-learning) (1.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pytorch-metric-learning) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pytorch-metric-learning) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-metric-learning) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->pytorch-metric-learning) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->pytorch-metric-learning) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.8/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imagehash) (1.22.4)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.8/dist-packages (from imagehash) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imagehash) (8.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from imagehash) (1.10.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.8/dist-packages (1.7.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-lr-finder in /usr/local/lib/python3.8/dist-packages (0.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from torch-lr-finder) (3.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-lr-finder) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torch-lr-finder) (23.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from torch-lr-finder) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-lr-finder) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=0.4.1->torch-lr-finder) (4.5.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->torch-lr-finder) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->torch-lr-finder) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->torch-lr-finder) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->torch-lr-finder) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->torch-lr-finder) (4.38.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->torch-lr-finder) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->torch-lr-finder) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop\n",
        "!pip install torch_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68lOvUCNNvmY",
        "outputId": "099b0c05-b804-4767-cd1e-491171ff4a88"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.8/dist-packages (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from thop) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->thop) (4.5.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_utils in /usr/local/lib/python3.8/dist-packages (0.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torch_utils) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->torch_utils) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "import os\n",
        "import cv2\n",
        "import timm\n",
        "\n",
        "import albumentations\n",
        "from albumentations import pytorch as AT\n",
        "\n",
        "#below are all from https://github.com/seefun/TorchUtils, thanks seefun to provide such useful tools\n",
        "import torch_utils as tu"
      ],
      "metadata": {
        "id": "rkyleS0gN8ri"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CLEAN_DATASET = 0\n",
        "FOLD = 5\n",
        "csv = pd.read_csv('clean_train_v4.csv') if CLEAN_DATASET else pd.read_csv('train.csv') #cleaned data has no obvious improvement\n",
        "print(csv.shape)\n",
        "sfolder = StratifiedKFold(n_splits=FOLD,random_state=709,shuffle=True)\n",
        "train_folds = []\n",
        "val_folds = []\n",
        "for i,(train_idx, val_idx) in enumerate(sfolder.split(csv['image'], csv['label'])):\n",
        "  train_folds.append(train_idx)\n",
        "  val_folds.append(val_idx)\n",
        "  print(len(train_idx), len(val_idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdbiB2hCPYal",
        "outputId": "af97c71b-0501-41bc-cd3d-d9581e76a35b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18353, 2)\n",
            "14682 3671\n",
            "14682 3671\n",
            "14682 3671\n",
            "14683 3670\n",
            "14683 3670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labelmap_list = sorted(list(set(csv['label']))) #sorting is necessary to reproduce the order of the labelmap\n",
        "labelmap = dict()\n",
        "for i, label in enumerate(labelmap_list):\n",
        "  labelmap[label] = i\n",
        "print(labelmap)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUS86stGn22w",
        "outputId": "41da4e19-6833-45eb-b344-adf02ec5ee2b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'abies_concolor': 0, 'abies_nordmanniana': 1, 'acer_campestre': 2, 'acer_ginnala': 3, 'acer_griseum': 4, 'acer_negundo': 5, 'acer_palmatum': 6, 'acer_pensylvanicum': 7, 'acer_platanoides': 8, 'acer_pseudoplatanus': 9, 'acer_rubrum': 10, 'acer_saccharinum': 11, 'acer_saccharum': 12, 'aesculus_flava': 13, 'aesculus_glabra': 14, 'aesculus_hippocastamon': 15, 'aesculus_pavi': 16, 'ailanthus_altissima': 17, 'albizia_julibrissin': 18, 'amelanchier_arborea': 19, 'amelanchier_canadensis': 20, 'amelanchier_laevis': 21, 'asimina_triloba': 22, 'betula_alleghaniensis': 23, 'betula_jacqemontii': 24, 'betula_lenta': 25, 'betula_nigra': 26, 'betula_populifolia': 27, 'broussonettia_papyrifera': 28, 'carpinus_betulus': 29, 'carpinus_caroliniana': 30, 'carya_cordiformis': 31, 'carya_glabra': 32, 'carya_ovata': 33, 'carya_tomentosa': 34, 'castanea_dentata': 35, 'catalpa_bignonioides': 36, 'catalpa_speciosa': 37, 'cedrus_atlantica': 38, 'cedrus_deodara': 39, 'cedrus_libani': 40, 'celtis_occidentalis': 41, 'celtis_tenuifolia': 42, 'cercidiphyllum_japonicum': 43, 'cercis_canadensis': 44, 'chamaecyparis_pisifera': 45, 'chamaecyparis_thyoides': 46, 'chionanthus_retusus': 47, 'chionanthus_virginicus': 48, 'cladrastis_lutea': 49, 'cornus_florida': 50, 'cornus_kousa': 51, 'cornus_mas': 52, 'crataegus_crus-galli': 53, 'crataegus_laevigata': 54, 'crataegus_phaenopyrum': 55, 'crataegus_pruinosa': 56, 'crataegus_viridis': 57, 'cryptomeria_japonica': 58, 'diospyros_virginiana': 59, 'eucommia_ulmoides': 60, 'evodia_daniellii': 61, 'fagus_grandifolia': 62, 'ficus_carica': 63, 'fraxinus_nigra': 64, 'fraxinus_pennsylvanica': 65, 'ginkgo_biloba': 66, 'gleditsia_triacanthos': 67, 'gymnocladus_dioicus': 68, 'halesia_tetraptera': 69, 'ilex_opaca': 70, 'juglans_cinerea': 71, 'juglans_nigra': 72, 'juniperus_virginiana': 73, 'koelreuteria_paniculata': 74, 'larix_decidua': 75, 'liquidambar_styraciflua': 76, 'liriodendron_tulipifera': 77, 'maclura_pomifera': 78, 'magnolia_acuminata': 79, 'magnolia_denudata': 80, 'magnolia_grandiflora': 81, 'magnolia_macrophylla': 82, 'magnolia_stellata': 83, 'magnolia_tripetala': 84, 'magnolia_virginiana': 85, 'malus_baccata': 86, 'malus_coronaria': 87, 'malus_floribunda': 88, 'malus_hupehensis': 89, 'malus_pumila': 90, 'metasequoia_glyptostroboides': 91, 'morus_alba': 92, 'morus_rubra': 93, 'nyssa_sylvatica': 94, 'ostrya_virginiana': 95, 'oxydendrum_arboreum': 96, 'paulownia_tomentosa': 97, 'phellodendron_amurense': 98, 'picea_abies': 99, 'picea_orientalis': 100, 'picea_pungens': 101, 'pinus_bungeana': 102, 'pinus_cembra': 103, 'pinus_densiflora': 104, 'pinus_echinata': 105, 'pinus_flexilis': 106, 'pinus_koraiensis': 107, 'pinus_nigra': 108, 'pinus_parviflora': 109, 'pinus_peucea': 110, 'pinus_pungens': 111, 'pinus_resinosa': 112, 'pinus_rigida': 113, 'pinus_strobus': 114, 'pinus_sylvestris': 115, 'pinus_taeda': 116, 'pinus_thunbergii': 117, 'pinus_virginiana': 118, 'pinus_wallichiana': 119, 'platanus_acerifolia': 120, 'platanus_occidentalis': 121, 'populus_deltoides': 122, 'populus_grandidentata': 123, 'populus_tremuloides': 124, 'prunus_pensylvanica': 125, 'prunus_sargentii': 126, 'prunus_serotina': 127, 'prunus_serrulata': 128, 'prunus_subhirtella': 129, 'prunus_virginiana': 130, 'prunus_yedoensis': 131, 'pseudolarix_amabilis': 132, 'ptelea_trifoliata': 133, 'pyrus_calleryana': 134, 'quercus_acutissima': 135, 'quercus_alba': 136, 'quercus_bicolor': 137, 'quercus_cerris': 138, 'quercus_coccinea': 139, 'quercus_imbricaria': 140, 'quercus_macrocarpa': 141, 'quercus_marilandica': 142, 'quercus_michauxii': 143, 'quercus_montana': 144, 'quercus_muehlenbergii': 145, 'quercus_nigra': 146, 'quercus_palustris': 147, 'quercus_phellos': 148, 'quercus_robur': 149, 'quercus_shumardii': 150, 'quercus_stellata': 151, 'quercus_velutina': 152, 'quercus_virginiana': 153, 'robinia_pseudo-acacia': 154, 'salix_babylonica': 155, 'salix_caroliniana': 156, 'salix_matsudana': 157, 'salix_nigra': 158, 'sassafras_albidum': 159, 'staphylea_trifolia': 160, 'stewartia_pseudocamellia': 161, 'styrax_japonica': 162, 'taxodium_distichum': 163, 'tilia_americana': 164, 'tilia_cordata': 165, 'tilia_europaea': 166, 'tilia_tomentosa': 167, 'tsuga_canadensis': 168, 'ulmus_americana': 169, 'ulmus_glabra': 170, 'ulmus_parvifolia': 171, 'ulmus_procera': 172, 'ulmus_pumila': 173, 'ulmus_rubra': 174, 'zelkova_serrata': 175}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LeavesDataset(Dataset):\n",
        "  def __init__(self, csv, transform=None):\n",
        "    self.csv = csv\n",
        "    self.transform = transform\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.csv['image'])\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    img = cv2.imread(self.csv['image'][idx])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    label = labelmap[self.csv['label'][idx]]\n",
        "    if self.transform:\n",
        "      img = self.transform(image = img)['image']\n",
        "    return img, torch.tensor(label).type(torch.LongTensor)\n",
        "\n",
        "def create_dls(train_csv, test_csv, train_transform, test_transform, bs, num_workers):\n",
        "  train_ds = LeavesDataset(train_csv, train_transform)\n",
        "  test_ds = LeavesDataset(test_csv, test_transform)\n",
        "  train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=num_workers, drop_last=True)\n",
        "  test_dl = DataLoader(test_ds, batch_size=bs, shuffle=False, num_workers=num_workers, drop_last=False)\n",
        "  return train_dl, test_dl, len(train_ds), len(test_ds)\n",
        "\n",
        "train_transform1 = albumentations.Compose([\n",
        "    albumentations.Resize(112, 112, interpolation=cv2.INTER_AREA),\n",
        "    albumentations.RandomRotate90(p=0.5),\n",
        "    albumentations.Transpose(p=0.5),\n",
        "    albumentations.Flip(p=0.5),\n",
        "    albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.0625, rotate_limit=45, border_mode=1, p=0.5),\n",
        "    #tu.randAugment(N=2,M=6,p=1,cut_out=True),    \n",
        "    albumentations.Normalize(),\n",
        "    AT.ToTensorV2(),\n",
        "    ])\n",
        "    \n",
        "test_transform1 = albumentations.Compose([\n",
        "    albumentations.Resize(112, 112, interpolation=cv2.INTER_AREA),\n",
        "    albumentations.Normalize(),\n",
        "    AT.ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "class LeavesTestDataset(Dataset):\n",
        "  def __init__(self, csv, transform=None):\n",
        "    self.csv = csv\n",
        "    self.transform = transform\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.csv['image'])\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    img = Image.open(self.csv['image'][idx])\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "    return img\n",
        "\n",
        "def create_testdls(test_csv, test_transform, bs):\n",
        "  test_ds = LeavesTestDataset(test_csv, test_transform)\n",
        "  test_dl = DataLoader(test_ds, batch_size=bs, shuffle=False, num_workers=2)\n",
        "  return test_dl\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "        transforms.Resize((112,112)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "def show_img(x):\n",
        "  trans = transforms.ToPILImage()\n",
        "  mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
        "  std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
        "  x = (x*std)+mean\n",
        "  x_pil = trans(x)\n",
        "  return x_pil"
      ],
      "metadata": {
        "id": "37J9DrvMn3Xo"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv = csv.iloc[train_folds[0]].reset_index()\n",
        "val_csv = csv.iloc[val_folds[0]].reset_index()"
      ],
      "metadata": {
        "id": "FJsCKdUW1-c2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl, val_dl, n_train, n_val = create_dls(train_csv, val_csv, train_transform=train_transform1, test_transform=test_transform1, bs=64, num_workers=4)\n",
        "     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-H5-b3L21rh",
        "outputId": "42ff5c16-1427-4beb-84e0-a9d23366d9c6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mixup_fn = Mixup(prob=1., switch_prob=0.0, onehot=True, label_smoothing=0.05, num_classes=176)\n",
        "for x, y in train_dl:\n",
        "  #imgs_train, labels_train = mixup_fn(x, y)\n",
        "  break"
      ],
      "metadata": {
        "id": "mO-5ZVzy3Ln5"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKTB6QUh3RX7",
        "outputId": "6fd831a7-df8f-4a62-c1ae-3c20947a4337"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_img((x[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "1EmGEtdU4suX",
        "outputId": "4c248d8d-9061-464c-eb95-a20502aaba79"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=112x112 at 0x7F153595DA60>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = timm.create_model('resnet50d', pretrained=True)"
      ],
      "metadata": {
        "id": "lmolmJ3p7Yjq"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = nn.Linear(model.fc.in_features, len(labelmap_list))\n",
        "nn.init.xavier_uniform_(model.fc.weight);"
      ],
      "metadata": {
        "id": "cfJtpoz_7ZJO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()\n",
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "aMp99oVq7cH1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelSmoothing(nn.Module):\n",
        "    \"\"\"NLL loss with label smoothing.\n",
        "    \"\"\"\n",
        "    def __init__(self, smoothing=0.0):\n",
        "        \"\"\"Constructor for the LabelSmoothing module.\n",
        "        :param smoothing: label smoothing factor\n",
        "        \"\"\"\n",
        "        super(LabelSmoothing, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
        "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
        "        nll_loss = nll_loss.squeeze(1)\n",
        "        smooth_loss = -logprobs.mean(dim=-1)\n",
        "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
        "        return loss.mean()"
      ],
      "metadata": {
        "id": "_xGKe-mx7eQE"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_1x = [param for name, param in model.named_parameters()\n",
        "             if name not in [\"fc.weight\", \"fc.bias\"]]\n",
        "lr = 5e-4\n",
        "\n",
        "optimizer = torch.optim.AdamW([{'params': params_1x},\n",
        "                                   {'params': model.fc.parameters(),\n",
        "                                    'lr': lr * 10}],\n",
        "                                lr=lr, weight_decay=0.001) #finetuning\n",
        "'''\n",
        "from optim import RangerLars\n",
        "optimizer = RangerLars([{'params': params_1x},\n",
        "                        {'params': model.fc.parameters(),\n",
        "                                    'lr': lr * 10}], lr=lr, weight_decay=0.001)\n",
        "'''\n",
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.001)\n",
        "\n",
        "loss_fn = LabelSmoothing(0.1)"
      ],
      "metadata": {
        "id": "AGSqKdj89Seh"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def find_lr(model, factor, train_dl, optimizer, loss_fn, device, init_lr=1e-8, final_lr=1e-1, beta=0.98, plot=True, save_dir=None):\n",
        "    num = len(train_dl) - 1\n",
        "    mult = (final_lr / init_lr) ** (1/num)\n",
        "    lr = init_lr\n",
        "    optimizer.param_groups[0]['lr'] = lr\n",
        "    avg_loss = 0.\n",
        "    best_loss = 0.\n",
        "    batch_num = 0\n",
        "    losses = []\n",
        "    log_lrs = []\n",
        "    scaler = torch.cuda.amp.GradScaler() # for AMP training \n",
        "    if 1:\n",
        "      for x, y in train_dl:\n",
        "          x, y = x.to(device), y.to(device)\n",
        "          batch_num += 1\n",
        "          optimizer.zero_grad()\n",
        "          with torch.cuda.amp.autocast():\n",
        "            out = model(x)\n",
        "            loss = loss_fn(out, y)\n",
        "          #smoothen the loss\n",
        "          avg_loss = beta * avg_loss + (1-beta) * loss.data.item() #check\n",
        "          smoothed_loss = avg_loss / (1 - beta**batch_num) #bias correction\n",
        "          #stop if loss explodes\n",
        "          if batch_num > 1 and smoothed_loss > 4 * best_loss: #prevents explosion\n",
        "              break\n",
        "          #record the best loss\n",
        "          if smoothed_loss < best_loss or batch_num == 1:\n",
        "              best_loss = smoothed_loss\n",
        "          #store the values\n",
        "          losses.append(smoothed_loss)\n",
        "          log_lrs.append(math.log10(lr))\n",
        "          #do the sgd step\n",
        "          #loss.backward()\n",
        "          #optimizer.step()\n",
        "          scaler.scale(loss).backward()\n",
        "          scaler.step(optimizer)\n",
        "          scaler.update()\n",
        "          #update the lr for the next step\n",
        "          lr *= mult\n",
        "          optimizer.param_groups[0]['lr'] = lr\n",
        "    #Suggest a learning rate\n",
        "    log_lrs, losses = np.array(log_lrs), np.array(losses)\n",
        "    idx_min = np.argmin(losses)\n",
        "    min_log_lr = log_lrs[idx_min]\n",
        "    lr_auto = (10 ** (min_log_lr)) /factor\n",
        "    if plot:\n",
        "        selected = [np.argmin(np.abs(log_lrs - (min_log_lr-1)))] #highlight the suggested lr\n",
        "        plt.figure()\n",
        "        plt.plot(log_lrs, losses,'-gD', markevery=selected)\n",
        "        plt.xlabel('log_lrs')\n",
        "        plt.ylabel('loss')\n",
        "        plt.title('LR Range Test')\n",
        "        if save_dir is not None:\n",
        "            plt.savefig(f'{save_dir}/lr_range_test.png')\n",
        "        else:\n",
        "            plt.savefig(f'lr_range_test.png')\n",
        "    return lr_auto"
      ],
      "metadata": {
        "id": "vouQQ7Bt9aFQ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3LD-hDGDWud",
        "outputId": "0c472b85-70c8-47d8-9aa1-6c86afadb03c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'torch_utils' from '/usr/local/lib/python3.8/dist-packages/torch_utils/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_learner(lr, nb, epochs, model_name='resnet50d', MIXUP=0.1):\n",
        "  mixup_fn = tu.Mixup(prob=MIXUP, switch_prob=0.0, onehot=True, label_smoothing=0.05, num_classes=len(labelmap_list))\n",
        "  model = timm.create_model(model_name, pretrained=True)\n",
        "  model.fc = nn.Linear(model.fc.in_features, len(labelmap_list))\n",
        "  nn.init.xavier_uniform_(model.fc.weight)\n",
        "  model.cuda()\n",
        "\n",
        "  params_1x = [param for name, param in model.named_parameters()\n",
        "              if name not in [\"fc.weight\", \"fc.bias\"]]\n",
        "\n",
        "  optimizer = torch.optim.AdamW([{'params': params_1x},\n",
        "                                    {'params': model.fc.parameters(),\n",
        "                                      'lr': lr*10}],\n",
        "                                  lr=lr, weight_decay=2e-4)\n",
        "\n",
        "  loss_fn = tu.SoftTargetCrossEntropy() if MIXUP else LabelSmoothing(0.1)\n",
        "  loss_fn_test = F.cross_entropy\n",
        "  '''\n",
        "  import math\n",
        "  def warmup_one_cycle(y1=0.0, y2=1.0, steps=100, warmup_steps=0): #no warmup is better experimentally\n",
        "          #sinusoidal ramp from y1 to y2 https://arxiv.org/pdf/1812.01187.pdf\n",
        "          return lambda x: x / warmup_steps if x < warmup_steps \\\n",
        "                          else ((1 - math.cos((x-warmup_steps) * math.pi / steps)) / 2) * (y2 - y1) + y1\n",
        "\n",
        "  lf = warmup_one_cycle(1, 0.2, epochs*nb, 3*nb)\n",
        "  #lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lf) \n",
        "    #lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5*nb, eta_min=lr_suggested/100)\n",
        "  '''\n",
        "  lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs*nb, eta_min=lr/20)\n",
        "  return model, optimizer, loss_fn, loss_fn_test, lr_scheduler, mixup_fn\n",
        "     "
      ],
      "metadata": {
        "id": "GJ_J8FjO9qnk"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Start training\n",
        "import time\n",
        "import ttach as tta\n",
        "device = 'cuda'\n",
        "save_dir = './gdrive/MyDrive/kaggle_leave_classification/'\n",
        "#map from idx to string\n",
        "labelmap_inverse = dict()\n",
        "for key_ in labelmap.keys():\n",
        "  labelmap_inverse[labelmap[key_]] = key_\n",
        "EPOCHS = 50\n",
        "MIXUP = 0.1\n",
        " \n",
        "scaler = torch.cuda.amp.GradScaler() # for AMP training \n",
        "\n",
        "for fold in range(FOLD):\n",
        "  print(f'Start Fold{fold}...')\n",
        "  train_csv = csv.iloc[train_folds[2]].reset_index()\n",
        "  val_csv = csv.iloc[val_folds[2]].reset_index()\n",
        "  train_dl, val_dl, n_train, n_val = create_dls(train_csv, val_csv, train_transform=train_transform1, test_transform=test_transform1, bs=64, num_workers=4)\n",
        "  model, optimizer, loss_fn, loss_fn_test, lr_scheduler, mixup_fn = get_learner(3e-4, len(train_dl), EPOCHS, model_name='resnet50d', MIXUP=MIXUP)\n",
        "  model_name = f'5fold_test_fold{fold}'\n",
        "  train_losses = [] \n",
        "  val_losses = []\n",
        "  train_accus = []\n",
        "  val_accus = []\n",
        "  best_accu = 0\n",
        "  best_loss = float('inf')\n",
        "  lrs = []\n",
        "  for epoch in range(EPOCHS):\n",
        "          t1 = time.time()\n",
        "          val_accu = 0\n",
        "          train_accu = 0\n",
        "          train_losses_tmp = []\n",
        "          #Train\n",
        "          model.train()\n",
        "          t_inf = 0\n",
        "          for x, y in train_dl:\n",
        "              if MIXUP:\n",
        "                x, y = mixup_fn(x, y)\n",
        "              x, y = x.to(device), y.to(device)\n",
        "              #Forward\n",
        "              with torch.cuda.amp.autocast():\n",
        "                pred = model(x)\n",
        "                loss = loss_fn(pred, y)\n",
        "              #Backward\n",
        "              #loss.backward()\n",
        "              #optimizer.step()\n",
        "              scaler.scale(loss).backward()\n",
        "              scaler.step(optimizer)\n",
        "              scaler.update()\n",
        "              lr_scheduler.step()\n",
        "              optimizer.zero_grad()\n",
        "              #Statistics\n",
        "              lrs.append(optimizer.param_groups[0]['lr']) #group 0,1,2 share the learning rate\n",
        "              train_losses_tmp.append(loss.data.item())\n",
        "              pred_labels = torch.argmax(pred.data, dim=1)\n",
        "              y_labels = torch.argmax(y.data, dim=1) if MIXUP else y.data\n",
        "              train_accu += (pred_labels==y_labels).float().sum()\n",
        "          t_inf /= len(train_dl)\n",
        "          train_losses.append(np.mean(np.array(train_losses_tmp)))\n",
        "          train_accu /= n_train\n",
        "          train_accus.append(train_accu.data.item())\n",
        "\n",
        "          t2 = time.time()\n",
        "          #Validation\n",
        "          val_losses_tmp = []\n",
        "          model.eval()\n",
        "          with torch.no_grad():\n",
        "            for x, y in val_dl:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                logit = model(x)\n",
        "                val_loss = loss_fn_test(logit, y) \n",
        "                val_losses_tmp.append(val_loss.data.item())\n",
        "                pred = torch.argmax(logit.data, dim=1)\n",
        "                val_accu += (pred==y.data).float().sum()\n",
        "          t3 = time.time()\n",
        "          val_loss = np.mean(np.array(val_losses_tmp))\n",
        "          val_losses.append(val_loss)\n",
        "          val_accu /= n_val\n",
        "          val_accus.append(val_accu.data.item())\n",
        "          print('fold', fold, 'epoch', epoch, 'train_loss', train_losses[epoch], 'val_loss', val_losses[epoch], 'val_accu', val_accu, 'train_accu', train_accu, 'train time', t2-t1, 'val time', t3-t2, 'lr[0]', lrs[-1])\n",
        "          if save_dir is not None:\n",
        "              if val_accu == best_accu:\n",
        "                  if val_loss < best_loss: #never satisfied\n",
        "                      checkpoint = {\"model\": model.state_dict()}\n",
        "                      torch.save(checkpoint, os.path.join(save_dir,f'{model_name}_best.pth'))\n",
        "                      print(f'Stored a new best model in {save_dir}')\n",
        "                      best_loss = val_loss\n",
        "              elif val_accu > best_accu:\n",
        "                  checkpoint = {\"model\": model.state_dict()}\n",
        "                  torch.save(checkpoint, os.path.join(save_dir,f'{model_name}_best.pth'))\n",
        "                  print(f'Stored a new best model in {save_dir}')\n",
        "                  best_accu = val_accu\n",
        "              '''\n",
        "              if epoch == EPOCHS - 1:\n",
        "                  checkpoint = {\"model\": model.state_dict()}\n",
        "                  torch.save(checkpoint, os.path.join(save_dir,f'{model_name}_last.pth'))\n",
        "                  print(f'Stored the last model in {save_dir}')\n",
        "              '''\n",
        "  #test time\n",
        "  test_csv = pd.read_csv('test.csv')\n",
        "  test_dl = create_testdls(test_csv, transform_test, bs=8)\n",
        "  model.eval()\n",
        "  tta_model = tta.ClassificationTTAWrapper(model, tta.aliases.flip_transform(),  merge_mode='mean')\n",
        "  tta_model.eval()\n",
        "  res = []\n",
        "  for x in test_dl:\n",
        "      x = x.to(device)\n",
        "      logit = tta_model(x)\n",
        "      pred = torch.argmax(logit.data, dim=1).cpu().numpy()\n",
        "      for i in range(len(pred)):\n",
        "          res.append(labelmap_inverse[pred[i]])\n",
        "  test_csv.insert(1, 'label', res)\n",
        "  \n",
        "  test_csv.to_csv(f'submission_e50{model_name}_fold{fold}.csv', index=False)\n",
        "  print('test cvs is saved')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "Z76B1TVG-g2u",
        "outputId": "8bc78cc8-a600-418c-8ed0-c87c4d93a650"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Fold0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-681fe8af7327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mval_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_folds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transform1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resnet50d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMIXUP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMIXUP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'5fold_test_fold{fold}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-0436b248b151>\u001b[0m in \u001b[0;36mget_learner\u001b[0;34m(lr, nb, epochs, model_name, MIXUP)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resnet50d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMIXUP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmixup_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMIXUP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswitch_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monehot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelmap_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelmap_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch_utils' has no attribute 'dataset'"
          ]
        }
      ]
    }
  ]
}